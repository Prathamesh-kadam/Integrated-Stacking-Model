{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMz1L+pexAlIdG8XaU+uoL5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Prathamesh-kadam/Integrated-Stacking-Model/blob/main/U_Net_Model_and_Integrated_Stacking_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**U-Net Model**"
      ],
      "metadata": {
        "id": "AeEeiayUVObG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acdlF5G7U79I"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio import warp\n",
        "from rasterio.enums import Resampling\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to scale the data to 0-255 range\n",
        "def scale_data(data):\n",
        "    min_value, max_value = np.percentile(data, [2, 98])\n",
        "    scaled_data = (data - min_value) / (max_value - min_value) * 255\n",
        "    scaled_data = np.clip(scaled_data, 0, 255)\n",
        "    return scaled_data.astype(np.uint8)\n",
        "\n",
        "# Function to convert data to decibel units and stretch within fixed thresholds\n",
        "def convert_to_db_and_stretch(data, lower_threshold, upper_threshold):\n",
        "    data_db = 10 * np.log10(data)\n",
        "    data_db = (data_db - lower_threshold) / (upper_threshold - lower_threshold) * 255\n",
        "    data_db = np.clip(data_db, 0, 255)\n",
        "    return data_db.astype(np.uint8)\n",
        "\n",
        "# Function to generate the mask library based on dB image and threshold values\n",
        "def generate_mask_lib(db_image):\n",
        "    # Define the threshold values for different ice types in dB\n",
        "    threshold_ice_free = [-7, -2]  # Ice Free threshold\n",
        "    threshold_ice_bergs = [-2, 3.5]  # Ice Covered threshold\n",
        "    threshold_multiyearice = [-1, 3.5]  # Multi-Year Ice threshold\n",
        "    threshold_firstyearice = [-2, -1]  # First-Year Ice threshold\n",
        "\n",
        "    # Generate the mask library based on the dB image and threshold values\n",
        "    mask_ice_free = (db_image >= threshold_ice_free[0]) & (db_image <= threshold_ice_free[1])\n",
        "    mask_ice_bergs = (db_image >= threshold_ice_bergs[0]) & (db_image <= threshold_ice_bergs[1])\n",
        "    mask_multiyearice = (db_image >= threshold_multiyearice[0]) & (db_image <= threshold_multiyearice[1])\n",
        "    mask_firstyearice = (db_image >= threshold_firstyearice[0]) & (db_image <= threshold_firstyearice[1])\n",
        "\n",
        "    mask_lib = {\n",
        "        'Ice Free': mask_ice_free.astype(int),\n",
        "        'Ice bergs': mask_ice_bergs.astype(int),\n",
        "        'Multi-Year Ice': mask_multiyearice.astype(int),\n",
        "        'First-Year Ice': mask_firstyearice.astype(int),\n",
        "    }\n",
        "\n",
        "    return mask_lib\n",
        "\n",
        "\n",
        "# Function to resize the HV image to match the dimensions of the HH image\n",
        "def resize_hv_data(hv_data, hv_transform, hh_transform, hh_shape):\n",
        "    hv_data_resized = np.empty(hh_shape, dtype=hv_data.dtype)\n",
        "    warp.reproject(\n",
        "        source=hv_data,\n",
        "        destination=hv_data_resized,\n",
        "        src_transform=hv_transform,\n",
        "        src_crs=hv_ds.crs,\n",
        "        dst_transform=hh_transform,\n",
        "        dst_crs=hh_ds.crs,\n",
        "        resampling=Resampling.nearest\n",
        "    )\n",
        "    return hv_data_resized\n",
        "\n",
        "# List the HH and HV file paths in the respective folders\n",
        "hh_folder = '/kaggle/input/eos4-hh-data'\n",
        "hv_folder = '/kaggle/input/eos4-hv-data'\n",
        "output_folder = '/kaggle/working/input'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "hh_files = os.listdir(hh_folder)\n",
        "hv_files = os.listdir(hv_folder)\n",
        "\n",
        "# Iterate over the files and process each pair of HH and HV images\n",
        "for hh_file, hv_file in zip(hh_files, hv_files):\n",
        "    hh_tif_file = os.path.join(hh_folder, hh_file)\n",
        "    hv_tif_file = os.path.join(hv_folder, hv_file)\n",
        "\n",
        "    with rasterio.open(hh_tif_file) as hh_ds:\n",
        "        hh_data = hh_ds.read(1)\n",
        "\n",
        "    with rasterio.open(hv_tif_file) as hv_ds:\n",
        "        hv_data = hv_ds.read(1)\n",
        "        hv_transform = hv_ds.transform\n",
        "\n",
        "        # Resize the HV image to match the dimensions of the HH image\n",
        "        hh_transform = hh_ds.transform\n",
        "        hv_data_resized = resize_hv_data(hv_data, hv_transform, hh_transform, hh_data.shape)\n",
        "\n",
        "    # Set zero and negative values in hv_data_resized to a small positive value to avoid warnings\n",
        "    hv_data_resized[hv_data_resized <= 0] = 1e-9\n",
        "\n",
        "    # Calculate the HH / HV ratio and HH - HV difference\n",
        "    hh_hv_ratio = hh_data / hv_data_resized\n",
        "    hh_hv_diff = hh_data - hv_data_resized\n",
        "\n",
        "    # Convert the data to dB units using the 'convert_to_db_and_stretch' function\n",
        "    hh_hv_ratio_db = convert_to_db_and_stretch(hh_hv_ratio, -7, 3.5)\n",
        "    hh_hv_diff_db = convert_to_db_and_stretch(hh_hv_diff, -7, 3.5)\n",
        "    hv = convert_to_db_and_stretch(hv_data_resized, -7, 3.5)\n",
        "\n",
        "    # Create gray-scale composite by combining the processed HH-HV ratio and HH-HV difference\n",
        "    gray_composite = 0.33*hv + 0.33 * hh_hv_ratio_db + 0.33 * hh_hv_diff_db\n",
        "\n",
        "    # Save the gray-scale composite as a TIFF file\n",
        "    output_tif_file = os.path.join('/kaggle/working/input', hh_file.replace('.tif', '_gray_composite.tif'))\n",
        "\n",
        "    with rasterio.open(output_tif_file, 'w', driver='GTiff', width=hh_ds.width, height=hh_ds.height, count=1, dtype=gray_composite.dtype) as dst:\n",
        "        dst.write(gray_composite, 1)\n",
        "\n",
        "    print(f\"Gray-scale composite image saved as {output_tif_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n",
        "from PIL import Image\n",
        "import warnings\n",
        "import tifffile as tiff\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "from tifffile import imread\n",
        "\n",
        "img_dir = '/kaggle/working/input'\n",
        "\n",
        "img_filenames = os.listdir(img_dir)\n",
        "img_names = [s.split('.')[0] for s in img_filenames if s.endswith('.tif')]\n",
        "\n",
        "img_ext = '.tif'"
      ],
      "metadata": {
        "id": "I9BpIoXEVLtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code is to display HH, HV and composite images. For each type (like HH, HV, Composite) we have to change the path of the folder to show the images"
      ],
      "metadata": {
        "id": "iQGc1iSMVm2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tifffile as tiff\n",
        "\n",
        "# Set the folder path containing the images\n",
        "folder_path = \"/kaggle/input/eos4-hv-data\"\n",
        "\n",
        "# Get a list of files in the folder\n",
        "file_list = os.listdir(folder_path)\n",
        "\n",
        "# Create a subplot grid to display the images\n",
        "num_images = len(file_list)\n",
        "num_rows = int(np.ceil(np.sqrt(num_images)))\n",
        "num_cols = int(np.ceil(num_images / num_rows))\n",
        "\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
        "\n",
        "# Iterate over each file in the folder\n",
        "for i, file_name in enumerate(file_list):\n",
        "    # Check if the file is an image (TIFF format)\n",
        "    if file_name.lower().endswith('.tif') or file_name.lower().endswith('.tif'):\n",
        "        # Get the directory path of the image file\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "        # Load and display the image using tifffile\n",
        "        image = tiff.imread(file_path)\n",
        "\n",
        "        # Determine the subplot indices\n",
        "        row_idx = i // num_cols\n",
        "        col_idx = i % num_cols\n",
        "\n",
        "        # Display the image in the corresponding subplot\n",
        "        axes[row_idx, col_idx].imshow(image, cmap='gray')\n",
        "        axes[row_idx, col_idx].axis('off')\n",
        "\n",
        "# Adjust the spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zzIB9zWfVZXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization"
      ],
      "metadata": {
        "id": "7I_l6rbUWNzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#no need for composite image data set as already normalization is  being done!!!\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Function to perform Min-Max normalization\n",
        "def normalize_backscattering(data):\n",
        "    min_value = np.min(data)\n",
        "    max_value = np.max(data)\n",
        "    normalized_data = 255 * (data - min_value) / (max_value - min_value)\n",
        "    normalized_data = normalized_data.astype(np.uint8)\n",
        "    return normalized_data\n",
        "\n",
        "# Folder path containing the TIFF files\n",
        "folder_path = '/kaggle/input/eos4-hv-data'  # Replace this with the actual path to your folder\n",
        "\n",
        "# Output folder for the normalized TIFF files\n",
        "norm_folder = '/kaggle/working/norm_data'  # Replace this with the desired output path\n",
        "\n",
        "# Check if the folder exists\n",
        "if not os.path.exists(folder_path):\n",
        "    print(f\"Folder not found: {folder_path}\")\n",
        "else:\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(norm_folder):\n",
        "        os.makedirs(norm_folder)\n",
        "\n",
        "    # Loop through each TIFF file in the folder\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.tiff') or filename.endswith('.tif'):\n",
        "            # Read the TIFF file\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            backscattering_data = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "            # Perform Min-Max normalization\n",
        "            normalized_data = normalize_backscattering(backscattering_data)\n",
        "\n",
        "            # Print the minimum and maximum values in the normalized backscattering data\n",
        "            min_value = np.min(normalized_data)\n",
        "            max_value = np.max(normalized_data)\n",
        "            print(f\"File: {filename}\")\n",
        "            print(\"Minimum value:\", min_value)\n",
        "            print(\"Maximum value:\", max_value)\n",
        "            print(\"\\n\")\n",
        "\n",
        "            # Save the normalized data as a new TIFF file\n",
        "            new_filename = \"normalized_\" + filename\n",
        "            new_file_path = os.path.join(norm_folder, new_filename)\n",
        "            cv2.imwrite(new_file_path, normalized_data)\n",
        "\n",
        "print(\"Normalization and saving complete!\")"
      ],
      "metadata": {
        "id": "yJ025efWViKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code is for producing individual mask image for each type of sea-ice. like for each image, mask for type 1 , another mask for type 2,.......and so on.\n",
        "\n",
        "\n",
        "Note: this code is currently used for composite image to do so, but can be done for individual HH and HV dataset also."
      ],
      "metadata": {
        "id": "UVVSmWipWk41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for composite images\n",
        "\n",
        "import numpy as np\n",
        "import tifffile as tiff\n",
        "from skimage.transform import resize\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def convert_to_db(image):\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        db_image = 10 * np.log10(image)\n",
        "    db_image[np.isinf(db_image)] = np.nan\n",
        "    return db_image\n",
        "\n",
        "def generate_mask_lib(db_image):\n",
        "    # Define the threshold values for different ice types in dB\n",
        "    threshold_ice_free = [-np.inf,-35]  # Ice Free threshold\n",
        "    threshold_ice_bergs = [-25,-15]  # Ice Covered threshold\n",
        "    threshold_multiyearice = [-15, np.inf]  # Multi-Year Ice threshold\n",
        "    threshold_firstyearice = [-35, -25]  # First-Year Ice threshold\n",
        "\n",
        "\n",
        "    # Generate the mask library based on the dB image and threshold values\n",
        "    mask_ice_free = (db_image >= threshold_ice_free[0]) & (db_image <= threshold_ice_free[1])\n",
        "    mask_ice_bergs = (db_image >= threshold_ice_bergs[0]) & (db_image <= threshold_ice_bergs[1])\n",
        "    mask_multiyearice = (db_image >= threshold_multiyearice[0]) & (db_image <= threshold_multiyearice[1])\n",
        "    mask_firstyearice = (db_image >= threshold_firstyearice[0]) & (db_image <= threshold_firstyearice[1])\n",
        "    #mask_icetype4 = (db_image >= threshold_icetype4[0]) & (db_image <= threshold_icetype4[1])\n",
        "    #mask_newice = (db_image >= threshold_newice[0]) & (db_image <= threshold_newice[1])\n",
        "\n",
        "    mask_lib = {\n",
        "        'Ice Free': mask_ice_free.astype(int),\n",
        "        'Ice bergs': mask_ice_bergs.astype(int),\n",
        "        'Multi-Year Ice': mask_multiyearice.astype(int),\n",
        "        'First-Year Ice': mask_firstyearice.astype(int),\n",
        "        #'Ice Type 4': mask_icetype4.astype(int),\n",
        "        #'New Ice': mask_newice.astype(int)\n",
        "    }\n",
        "\n",
        "    return mask_lib\n",
        "\n",
        "# Folder path containing the SAR images\n",
        "folder_path = \"/kaggle/working/input\"\n",
        "folder_path2 = \"/kaggle/input/images-mask20\"\n",
        "output_folder = \"/kaggle/working/output\"\n",
        "\n",
        "# Initialize the dictionaries to store the percentages for each ice type\n",
        "total_percentages = {ice_type: 0 for ice_type in ['Ice Free', 'Ice Covered', 'Multi-Year Ice', 'First-Year Ice']}\n",
        "label_to_int = {'Ice Free': 0, 'Ice bergs': 2, 'Multi-Year Ice': 3, 'First-Year Ice': 1}\n",
        "\n",
        "num_images = 0\n",
        "y = []\n",
        "x = []\n",
        "z = []\n",
        "\n",
        "# Check if the output folder exists\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate through the images in the folder\n",
        "for image_file in os.listdir(folder_path):\n",
        "    if image_file.endswith(\".tif\"):\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        mask_path = os.path.join(folder_path2, image_file)\n",
        "\n",
        "        # Load and preprocess the SAR image\n",
        "        image = tiff.imread(image_path)\n",
        "        image = resize(image, (256, 256))\n",
        "        db_image = convert_to_db(image)\n",
        "\n",
        "            # Print the maximum and minimum values of the dB image\n",
        "        print(f\"Image: {image_file}\")\n",
        "        print(\"Max dB value:\", np.nanmax(db_image))\n",
        "        print(\"Min dB value:\", np.nanmin(db_image))\n",
        "\n",
        "        # Generate the mask library for the dB image\n",
        "        mask_lib = generate_mask_lib(db_image)\n",
        "\n",
        "        # Save the mask images to the output folder\n",
        "        for ice_type, mask_image in mask_lib.items():\n",
        "            output_path = os.path.join(output_folder, image_file.replace(\".tif\", f\"_{ice_type}_mask.png\"))\n",
        "            mask_image = (mask_image * 255).astype(np.uint8)\n",
        "            tiff.imsave(output_path, mask_image)\n",
        "\n",
        "            # Display the mask image\n",
        "            plt.imshow(mask_image, cmap='gray')\n",
        "            plt.axis('off')\n",
        "            plt.title(ice_type)\n",
        "            plt.show()"
      ],
      "metadata": {
        "id": "JDI4hoKhWRqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code is to produce the mask image for the dataset which will be combination of different sea ice type show with a colour combination ranging from black to white with colour lable bar."
      ],
      "metadata": {
        "id": "IMD8VXrYXXrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage.transform import resize\n",
        "import os\n",
        "import shutil\n",
        "import tifffile as tiff\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def convert_to_db(image):\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        db_image = 10 * np.log10(image)\n",
        "    return db_image\n",
        "\n",
        "def generate_mask_lib(db_image):\n",
        "    # Define the threshold values for different ice types in dB\n",
        "    threshold_ice_free = [-7, -2]  # Ice Free threshold\n",
        "    threshold_ice_bergs = [-2, 3.5]  # Ice Covered threshold\n",
        "    threshold_multiyearice = [-1, 3.5]  # Multi-Year Ice threshold\n",
        "    threshold_firstyearice = [-2, -1]  # First-Year Ice threshold\n",
        "\n",
        "    # Generate the mask library based on the dB image and threshold values\n",
        "    mask_ice_free = (db_image >= threshold_ice_free[0]) & (db_image <= threshold_ice_free[1])\n",
        "    mask_ice_bergs = (db_image >= threshold_ice_bergs[0]) & (db_image <= threshold_ice_bergs[1])\n",
        "    mask_multiyearice = (db_image >= threshold_multiyearice[0]) & (db_image <= threshold_multiyearice[1])\n",
        "    mask_firstyearice = (db_image >= threshold_firstyearice[0]) & (db_image <= threshold_firstyearice[1])\n",
        "\n",
        "    mask_lib = {\n",
        "        'Ice Free': mask_ice_free.astype(int),\n",
        "        'Ice bergs': mask_ice_bergs.astype(int),\n",
        "        'Multi-Year Ice': mask_multiyearice.astype(int),\n",
        "        'First-Year Ice': mask_firstyearice.astype(int),\n",
        "    }\n",
        "\n",
        "    return mask_lib\n",
        "\n",
        "# Set the folder path where the images are located\n",
        "folder_path = \"/kaggle/working/norm_data\"  # Change this to the path of your image folder\n",
        "\n",
        "# Set the folder where you want to save the masks\n",
        "mask_output_folder = \"/kaggle/working/combined-mask\"  # Change this to your desired mask output folder path\n",
        "if os.path.exists(mask_output_folder):\n",
        "    shutil.rmtree(mask_output_folder)\n",
        "os.makedirs(mask_output_folder)\n",
        "\n",
        "# Lists to store images, masks, and labels\n",
        "x = []\n",
        "z = []\n",
        "y = []\n",
        "\n",
        "# Define custom colors for the colorbar ticks based on ice types\n",
        "colors = ['black', 'lightgray', 'white', 'white']\n",
        "\n",
        "# Iterate through the images in the folder\n",
        "for image_file in os.listdir(folder_path):\n",
        "    if image_file.endswith(\".tif\"):\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "\n",
        "        # Load and preprocess the SAR image\n",
        "        image = tiff.imread(image_path)\n",
        "        image = resize(image, (256, 256))\n",
        "        db_image = convert_to_db(image)\n",
        "\n",
        "        # Handle NaN and Inf values in db_image\n",
        "        db_image[np.isnan(db_image)] = np.nanmin(db_image)\n",
        "        finite_max = np.nanmax(db_image[np.isfinite(db_image)])\n",
        "        db_image[np.isinf(db_image)] = finite_max + 1\n",
        "\n",
        "        # Generate the mask library for the dB image\n",
        "        mask_lib = generate_mask_lib(db_image)\n",
        "\n",
        "        # Initialize an empty color mask image\n",
        "        color_mask = np.zeros((db_image.shape[0], db_image.shape[1]), dtype=np.uint8)\n",
        "\n",
        "        # Assign values for different ice types in the color mask image\n",
        "        color_mask[mask_lib['Ice Free'] == 1] = 0      # Assign value 1 for Ice Free\n",
        "        color_mask[mask_lib['Ice bergs'] == 1] = 1     # Assign value 2 for Ice bergs\n",
        "        color_mask[mask_lib['Multi-Year Ice'] == 1] = 2   # Assign value 3 for Multi-Year Ice\n",
        "        color_mask[mask_lib['First-Year Ice'] == 1] = 3   # Assign value 4 for First-Year Ice\n",
        "\n",
        "        # Save the color mask image to the output folder with the image name\n",
        "        mask_image_name = image_file.replace(\".tif\", \"_color_mask.tif\")\n",
        "        mask_output_path = os.path.join(mask_output_folder, mask_image_name)  # Use the mask_output_folder\n",
        "        tiff.imsave(mask_output_path, color_mask)\n",
        "\n",
        "        # Add image, mask, and label to the lists\n",
        "        x.append(image)\n",
        "        z.append(color_mask)\n",
        "        y.append(mask_lib)\n",
        "\n",
        "        # Show the color mask image with a colorbar\n",
        "        plt.imshow(color_mask, cmap='gray')\n",
        "        plt.colorbar(label='Ice Types')  # Add a colorbar with label\n",
        "        plt.axis('off')\n",
        "        plt.title(\"Mask for Image: \" + image_file)\n",
        "\n",
        "        # Show the color mask image with a colorbar\n",
        "        plt.imshow(color_mask, cmap='gray')\n",
        "        cbar = plt.colorbar(label='Ice Types', ticks=[0, 1, 2, 3], format='%d', orientation='vertical', pad=0.02, aspect=40)\n",
        "        cbar.set_ticklabels(list(mask_lib.keys()))  # Assign custom labels to the colorbar ticks\n",
        "        plt.axis('off')\n",
        "        plt.title(\"Mask for Image: \" + image_file)\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# # Convert lists to numpy arrays for further processing if needed\n",
        "# x = np.array(x)\n",
        "# z = np.array(z)\n",
        "# y = np.array(y)\n",
        "\n",
        "# # Print the shapes of the images, masks, and labels\n",
        "# print(\"Shape of x (images):\", x.shape)\n",
        "# print(\"Shape of z (masks):\", z.shape)\n",
        "# print(\"Shape of y (labels):\", y.shape)\n"
      ],
      "metadata": {
        "id": "hWw34AFYW_W_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get to knwo the unique lable and ensure the lables are within the desired range"
      ],
      "metadata": {
        "id": "PAkUK7xhX_Ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step 1: Print the unique values in z_train\n",
        "unique_labels = np.unique(z)\n",
        "print(\"Unique labels in z:\", unique_labels)\n",
        "\n",
        "# Step 2: Check if the labels are integers and within the correct range\n",
        "num_classes = 4\n",
        "if np.issubdtype(z.dtype, np.integer):\n",
        "    min_label = np.min(z)\n",
        "    max_label = np.max(z)\n",
        "    if min_label >= 0 and max_label <= (num_classes - 1):\n",
        "        print(\"Labels are integers and within the correct range (0 to\", num_classes - 1, \")\")\n",
        "    else:\n",
        "        print(\"Labels are integers, but they are not within the correct range.\")\n",
        "        print(\"Minimum label:\", min_label, \", Maximum label:\", max_label)\n",
        "else:\n",
        "    print(\"Labels are not integers.\")"
      ],
      "metadata": {
        "id": "qnQ_RVByXm27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To plot the bar chart for the percentange of each seaice type in the dataset."
      ],
      "metadata": {
        "id": "ohNlzUHZYUg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tifffile as tiff\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize an empty dictionary to store the counts for each ice type\n",
        "ice_counts = {ice_type: 0 for ice_type in ['Ice Free', 'Ice bergs', 'Multi-Year Ice', 'First-Year Ice']}\n",
        "\n",
        "# Total number of images\n",
        "total_images = len(y)\n",
        "\n",
        "# Iterate through the labels (y list)\n",
        "for label in y:\n",
        "    for ice_type, mask in label.items():\n",
        "        ice_counts[ice_type] += np.sum(mask)\n",
        "\n",
        "# Convert the counts to percentages of total pixels\n",
        "total_pixels = 256 * 256 * total_images\n",
        "ice_percentages = {ice_type: (count / total_pixels) * 100 for ice_type, count in ice_counts.items()}\n",
        "\n",
        "# Generate the bar graph\n",
        "ice_types = list(ice_percentages.keys())\n",
        "percentages = list(ice_percentages.values())\n",
        "\n",
        "plt.bar(ice_types, percentages)\n",
        "plt.xlabel(\"Ice Types\")\n",
        "plt.ylabel(\"Percentage of Pixels\")\n",
        "plt.title(\"Ice Type Distribution\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E6gNcXvRYLac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation\n",
        "This is to make our dataset large enough to train our model effectively with better accuracy and results"
      ],
      "metadata": {
        "id": "er4Y_rf7YmKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage.transform import resize\n",
        "import os\n",
        "import shutil\n",
        "import tifffile as tiff\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=5,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Define the directory to save the augmented images\n",
        "augm_img = '/kaggle/working/augm_img'\n",
        "# Define the directory to save the augmented mask\n",
        "augm_mask = '/kaggle/working/augm_mask'\n",
        "\n",
        "# Clear the directory for images if it exists and is not empty\n",
        "if os.path.exists(augm_img):\n",
        "    shutil.rmtree(augm_img)\n",
        "os.makedirs(augm_img)\n",
        "# Clear the directory for masks if it exists and is not empty\n",
        "if os.path.exists(augm_mask):\n",
        "    shutil.rmtree(augm_mask)\n",
        "os.makedirs(augm_mask)\n",
        "\n",
        "# Create augmented images and labels\n",
        "print('Performing data augmentation')\n",
        "num_augmented_samples = 10  # Number of augmented samples to generate per original image\n",
        "\n",
        "# Function to apply data augmentation to the mask\n",
        "def augment_mask(mask):\n",
        "    mask[mask == 0] = 0   # Original mask value: 0 -> Augmented mask value: 85\n",
        "    mask[mask == 1] = 1  # Original mask value: 1 -> Augmented mask value: 170\n",
        "    mask[mask == 2] = 2  # Original mask value: 2 -> Augmented mask value: 255\n",
        "    return mask.astype(np.uint8)\n",
        "\n",
        "# Lists to store augmented images and masks\n",
        "augmented_images = []\n",
        "augmented_masks = []\n",
        "\n",
        "for i in range(len(x)):\n",
        "    img = x[i]\n",
        "    mask = z[i]\n",
        "\n",
        "    # Reshape the image to include the channel dimension\n",
        "    img = np.reshape(img, (*img.shape, 1))\n",
        "    # Reshape the mask to include the channel dimension\n",
        "    mask = np.reshape(mask, (*mask.shape, 1))\n",
        "\n",
        "    # Generate augmented images and masks\n",
        "    img_augmented_gen = datagen.flow(np.expand_dims(img, axis=0), batch_size=1, shuffle=False)\n",
        "    mask_augmented_gen = datagen.flow(np.expand_dims(mask, axis=0), batch_size=1, shuffle=False)\n",
        "\n",
        "    for j in range(num_augmented_samples):\n",
        "        img_augmented = img_augmented_gen.next()[0]\n",
        "        mask_augmented = mask_augmented_gen.next()[0]\n",
        "\n",
        "        # Resize the augmented image to a consistent size\n",
        "        #img_augmented = resize(img_augmented, (256, 256))\n",
        "        # Resize the augmented mask to a consistent size\n",
        "        #mask_augmented = resize(mask_augmented, (256, 256))\n",
        "\n",
        "        # Apply data augmentation to the mask (restore original mask values)\n",
        "        mask_augmented = augment_mask(mask_augmented)\n",
        "\n",
        "        # Save the augmented image and mask as TIFF files\n",
        "        img_save_path = os.path.join(augm_img, f'image_{i}_{j}.tif')\n",
        "        mask_save_path = os.path.join(augm_mask, f'image_{i}_{j}-mask.tif')\n",
        "\n",
        "        tiff.imwrite(img_save_path, img_augmented)\n",
        "        tiff.imwrite(mask_save_path, mask_augmented)\n",
        "\n",
        "        # Append the augmented images and masks to their respective lists\n",
        "        augmented_images.append(img_augmented)\n",
        "        augmented_masks.append(mask_augmented)\n",
        "\n",
        "# Convert the lists to arrays\n",
        "augmented_images = np.array(augmented_images)\n",
        "augmented_masks = np.array(augmented_masks)\n",
        "\n",
        "# Print the shapes of the augmented images and masks arrays\n",
        "print('Augmented images shape:', augmented_images.shape)\n",
        "print('Augmented masks shape:', augmented_masks.shape)\n",
        "print('Augmented images saved in:', augm_img)\n",
        "print('Augmented masks saved in:', augm_mask)"
      ],
      "metadata": {
        "id": "QPh1YQaHYchB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the augmentated dataset\n",
        "\n",
        "Note: this same can be used to plot the augmentated Image dataset and augmentated mask dataset. We just have to change the path of the folder."
      ],
      "metadata": {
        "id": "EDzU9NmeZAce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tifffile as tiff\n",
        "\n",
        "# Set the folder path containing the images\n",
        "folder_path = \"/kaggle/working/augm_mask\"\n",
        "\n",
        "# Get a list of files in the folder\n",
        "file_list = os.listdir(folder_path)\n",
        "\n",
        "# Create a subplot grid to display the images\n",
        "num_images = len(file_list)\n",
        "num_rows = int(np.ceil(np.sqrt(num_images)))\n",
        "num_cols = int(np.ceil(num_images / num_rows))\n",
        "\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
        "\n",
        "# Iterate over each file in the folder\n",
        "for i, file_name in enumerate(file_list):\n",
        "    # Check if the file is a TIFF image\n",
        "    if file_name.endswith('.tif'):\n",
        "        # Get the directory path of the image file\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "        # Load and display the image\n",
        "        image = tiff.imread(file_path)\n",
        "\n",
        "        # Determine the subplot indices\n",
        "        row_idx = i // num_cols\n",
        "        col_idx = i % num_cols\n",
        "\n",
        "        # Display the image in the corresponding subplot\n",
        "        axes[row_idx, col_idx].imshow(image, cmap='gray')\n",
        "        axes[row_idx, col_idx].axis('off')\n",
        "\n",
        "# Adjust the spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AauS52iKY5hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After augmentation, We have to split the dataset."
      ],
      "metadata": {
        "id": "5i835MQ5Zdba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "\n",
        "# Combine the augmented images and masks into a list of tuples\n",
        "data = list(zip(augmented_images, augmented_masks))\n",
        "\n",
        "# Shuffle the list of tuples\n",
        "random.shuffle(data)\n",
        "\n",
        "# Unpack the shuffled list of tuples back into separate lists\n",
        "shuffled_images, shuffled_masks = zip(*data)\n",
        "\n",
        "# Perform the train-test split on the shuffled lists\n",
        "x_train, x_test, z_train, z_test = train_test_split(shuffled_images, shuffled_masks, test_size=0.2, random_state=0)\n",
        "\n",
        "# Convert the lists to numpy arrays\n",
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "z_train = np.array(z_train)\n",
        "z_test = np.array(z_test)\n",
        "\n",
        "# Print the shapes of the resulting splits\n",
        "print(\"Training data - Input:\", x_train.shape)\n",
        "print(\"Training data - Mask:\", z_train.shape)\n",
        "print(\"Test data - Input:\", x_test.shape)\n",
        "print(\"Test data - Mask:\", z_test.shape)"
      ],
      "metadata": {
        "id": "21pWLxMJZEaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "import os\n",
        "import tifffile as tiff\n",
        "\n",
        "# Define the destination directories for train and test data of x\n",
        "x_train_dest = \"/kaggle/working/x_train\"\n",
        "x_test_dest = \"/kaggle/working/x_test\"\n",
        "# Define the destination directories for train and test data of z\n",
        "z_train_dest = \"/kaggle/working/z_train\"\n",
        "z_test_dest = \"/kaggle/working/z_test\"\n",
        "\n",
        "# Clear the directories if they exist and are not empty\n",
        "for directory in [x_train_dest, x_test_dest, z_train_dest, z_test_dest]:\n",
        "    if os.path.exists(directory):\n",
        "        shutil.rmtree(directory)\n",
        "    os.makedirs(directory)\n",
        "\n",
        "# Loop over the x_train data and store in the train directory\n",
        "for i, x_train_data in enumerate(x_train):\n",
        "    file_name = f\"x_train_{i}.tif\"\n",
        "    x_train_path = os.path.join(x_train_dest, file_name)\n",
        "\n",
        "    # Save the x_train_data as a TIFF file\n",
        "    tiff.imsave(x_train_path, x_train_data)\n",
        "\n",
        "# Loop over the x_test data and store in the test directory\n",
        "for i, x_test_data in enumerate(x_test):\n",
        "    file_name = f\"x_test_{i}.tif\"\n",
        "    x_test_path = os.path.join(x_test_dest, file_name)\n",
        "\n",
        "    # Save the x_test_data as a TIFF file\n",
        "    tiff.imsave(x_test_path, x_test_data)\n",
        "\n",
        "# Loop over the z_train data and store in the train directory\n",
        "for i, z_train_data in enumerate(z_train):\n",
        "    file_name = f\"z_train_{i}.tif\"\n",
        "    z_train_path = os.path.join(z_train_dest, file_name)\n",
        "\n",
        "    # Save the z_train_data as a TIFF file\n",
        "    tiff.imsave(z_train_path, z_train_data)\n",
        "\n",
        "# Loop over the z_test data and store in the test directory\n",
        "for i, z_test_data in enumerate(z_test):\n",
        "    file_name = f\"z_test_{i}.tif\"\n",
        "    z_test_path = os.path.join(z_test_dest, file_name)\n",
        "\n",
        "    # Save the z_test_data as a TIFF file\n",
        "    tiff.imsave(z_test_path, z_test_data)"
      ],
      "metadata": {
        "id": "bbLYOdirZhoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import tifffile as tiff\n",
        "import numpy as np\n",
        "\n",
        "x_train_dest = \"/kaggle/working/x_train\"\n",
        "x_test_dest = \"/kaggle/working/x_test\"\n",
        "z_train_dest = \"/kaggle/working/z_train\"\n",
        "z_test_dest = \"/kaggle/working/z_test\"\n",
        "\n",
        "def read_image(image_name):\n",
        "    def _read_image(image_name):\n",
        "        image_name_str = image_name.numpy().decode('utf-8')  # Convert image_name tensor to a string\n",
        "        image = tiff.imread(os.path.join(x_train_dest, image_name_str))\n",
        "        image = tf.convert_to_tensor(image, dtype=tf.float32) / 255.0\n",
        "\n",
        "        mask = tiff.imread(os.path.join(z_train_dest, f\"{image_name_str.split('.')[0]}-mask.tif\"))\n",
        "        mask = tf.convert_to_tensor(mask, dtype=tf.uint8)\n",
        "        return image, mask\n",
        "\n",
        "    return tf.py_function(_read_image, [image_name], [tf.float32, tf.uint8])\n",
        "\n",
        "# List all files in the x_train folder and x_test folder\n",
        "x_train_list = np.array([file for file in os.listdir(x_train_dest) if file.endswith(\".tif\")])\n",
        "x_test_list = np.array([file for file in os.listdir(x_test_dest) if file.endswith(\".tif\")])\n",
        "\n",
        "TRAIN_LENGTH = len(x_train_list)\n",
        "VAL_LENGTH = len(x_test_list)\n",
        "BATCH_SIZE = 4\n",
        "BUFFER_SIZE = 1000\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
        "\n",
        "ds_train = tf.data.Dataset.from_tensor_slices(x_train_list)\n",
        "ds_train = ds_train.map(read_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_dataset = ds_train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "ds_val = tf.data.Dataset.from_tensor_slices(x_test_list)\n",
        "ds_val = ds_val.map(read_image)\n",
        "val_dataset = ds_val.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "fQri5Fv3ZxnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "U-Net model architecture"
      ],
      "metadata": {
        "id": "XOLjHo8BaOZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout\n",
        "from tensorflow.keras import Model\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "IMG_CHANNELS = 1\n",
        "def get_unet(input_shape):\n",
        "    inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "    s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
        "\n",
        "    #Contraction path\n",
        "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
        "    c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
        "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
        "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
        "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
        "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
        "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "    #Expansive path\n",
        "    u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = tf.keras.layers.concatenate([u6, c4])\n",
        "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
        "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "\n",
        "    u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = tf.keras.layers.concatenate([u7, c3])\n",
        "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
        "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "\n",
        "    u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = tf.keras.layers.concatenate([u8, c2])\n",
        "    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
        "    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "\n",
        "    u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
        "    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
        "    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "\n",
        "    # Inside the get_unet function\n",
        "    outputs = tf.keras.layers.Conv2D(4, (1, 1), activation='softmax')(c9)\n",
        "\n",
        "\n",
        "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "IMG_SIZE = (256, 256,1)\n",
        "cmap = plt.cm.get_cmap('viridis')   # New colormap\n",
        "n_colors = len(cmap.colors)\n",
        "model = get_unet(IMG_SIZE)\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)\n"
      ],
      "metadata": {
        "id": "K0RUtJFIaND2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to generate a mask from the model predictions\n",
        "def create_mask(pred_mask, ele=0):\n",
        "    pred_mask = tf.argmax(pred_mask, axis=-1)#use the highest proabbaility class as the prediction\n",
        "    pred_mask = pred_mask[..., tf.newaxis]\n",
        "    return pred_mask[ele]\n",
        "\n",
        "#helper functions to plot image, mask, and predicted mask while training\n",
        "def show_predictions(dataset=None, num=1, ele=0):\n",
        "    if dataset:\n",
        "        for image, mask in dataset.take(num):\n",
        "            pred_mask = model.predict(image)\n",
        "            display([image[ele], mask[ele], create_mask(pred_mask, ele)])\n",
        "    else:\n",
        "        display([image, mask, create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n",
        "\n",
        "#function to display loss during training\n",
        "def plot_loss_acc(loss, val_loss, epoch):#, acc, val_acc, epoch):\n",
        "\n",
        "    epochs = range(epoch+1)\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,5))\n",
        "\n",
        "    ax.plot(epochs, loss, 'r', label='Training loss')\n",
        "    ax.plot(epochs, val_loss, 'bo', label='Validation loss')\n",
        "    ax.set_title('Training and Validation Loss')\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Loss Value')\n",
        "    ax.legend()\n",
        "    plt.show()\n",
        "\n",
        "#callback to clear output and show predictions\n",
        "from IPython.display import clear_output\n",
        "\n",
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.loss = []\n",
        "        self.val_loss = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        self.loss.append(logs['loss'])\n",
        "        self.val_loss.append(logs['val_loss'])\n",
        "\n",
        "        show_predictions()\n",
        "        plot_loss_acc(self.loss, self.val_loss, epoch)\n",
        "\n",
        "#callback to reduce learning rate when loss plateaus\n",
        "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=8, verbose=1,)\n",
        "\n",
        "#Define IoU metric (by stack overflow user HuckleberryFinn)\n",
        "class UpdatedMeanIoU(tf.keras.metrics.MeanIoU):\n",
        "    def __init__(self,\n",
        "               y_true=None,\n",
        "               y_pred=None,\n",
        "               num_classes=None,\n",
        "               name=None,\n",
        "               dtype=None):\n",
        "        super(UpdatedMeanIoU, self).__init__(num_classes = num_classes,name=name, dtype=dtype)\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_pred = tf.math.argmax(y_pred, axis=-1)\n",
        "        return super().update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "checkpoint_path = \"training/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights every 5 epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_freq=5*BATCH_SIZE)"
      ],
      "metadata": {
        "id": "wELSGjsKaZpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=2),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "]"
      ],
      "metadata": {
        "id": "-ED29uyrafsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Convert the mask data to one-hot encoded format\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Convert the mask data to one-hot encoded format\n",
        "z_train_one_hot = to_categorical(z_train, num_classes=4)\n",
        "z_test_one_hot = to_categorical(z_test, num_classes=4)\n",
        "print(z_train_one_hot.shape)\n",
        "print(z_test_one_hot.shape)"
      ],
      "metadata": {
        "id": "tgJrkMi1am92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and validating the model"
      ],
      "metadata": {
        "id": "ZAXeGKuPashL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomIoU(tf.keras.metrics.Metric):\n",
        "    def __init__(self, num_classes, name='custom_iou', **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.num_classes = num_classes\n",
        "        self.total_iou = self.add_weight(name='total_iou', initializer='zeros')\n",
        "        self.total_samples = self.add_weight(name='total_samples', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_pred = tf.argmax(y_pred, axis=-1)\n",
        "        y_true = tf.argmax(y_true, axis=-1)\n",
        "        iou = []\n",
        "        for i in range(self.num_classes):\n",
        "            intersection = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, i), tf.equal(y_pred, i)), dtype=tf.float32))\n",
        "            union = tf.reduce_sum(tf.cast(tf.logical_or(tf.equal(y_true, i), tf.equal(y_pred, i)), dtype=tf.float32))\n",
        "            iou.append(intersection / union)\n",
        "        self.total_iou.assign_add(tf.reduce_mean(iou))\n",
        "        self.total_samples.assign_add(1)\n",
        "\n",
        "    def result(self):\n",
        "        return self.total_iou / self.total_samples\n",
        "\n",
        "#train model\n",
        "model=get_unet(IMG_SIZE)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['categorical_accuracy', CustomIoU(num_classes=4)],\n",
        "              run_eagerly=True)\n",
        "\n",
        "EPOCHS = 25\n",
        "VAL_SUBSPLITS = 5\n",
        "VALIDATION_STEPS = VAL_LENGTH//BATCH_SIZE//VAL_SUBSPLITS\n",
        "\n",
        "model_history = model.fit(x_train,\n",
        "                          z_train_one_hot,\n",
        "                          epochs=EPOCHS,\n",
        "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                          validation_steps=VALIDATION_STEPS,\n",
        "                          validation_data=(x_test, z_test_one_hot),\n",
        "                          #callbacks=[DisplayCallback(), lr_callback, cp_callback]\n",
        "                         )\n",
        "\n",
        "# Retrieve validation loss and accuracy from the model history\n",
        "val_loss = model_history.history['loss']\n",
        "val_acc = model_history.history['categorical_accuracy']\n",
        "\n",
        "print(\"Validation Loss:\", val_loss)\n",
        "print(\"Validation Accuracy:\", val_acc)"
      ],
      "metadata": {
        "id": "zEOC290LarVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training the model, We have to get the prediction from the model by plotting the predicted mask image"
      ],
      "metadata": {
        "id": "YgLmRVD5a1HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "def display(display_list):\n",
        "    fig, axs = plt.subplots(nrows=1, ncols=len(display_list), figsize=(15, 6))\n",
        "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "    cmap = cm.get_cmap('gray')  # Use 'gray' colormap\n",
        "\n",
        "    for i in range(len(display_list)):\n",
        "        axs[i].set_title(title[i])\n",
        "        if i == 0:\n",
        "            # Convert 3D tensor to 2D tensor and then transpose\n",
        "            axs[i].imshow(tf.transpose(tf.squeeze(display_list[i]), perm=[1, 0]), cmap=cmap)\n",
        "        else:\n",
        "            msk = axs[i].imshow(display_list[i], cmap=cmap)\n",
        "        axs[i].axis('off')\n",
        "\n",
        "    # Plot colorbar\n",
        "    cbar = fig.colorbar(msk, ax=axs)\n",
        "    plt.show()\n",
        "\n",
        "# Get an iterator for the dataset\n",
        "x_train_iter = iter(x_train)\n",
        "z_train_iter = iter(z_train)\n",
        "\n",
        "# Get a single image and mask from the iterator\n",
        "image = next(x_train_iter)\n",
        "mask = next(z_train_iter)\n",
        "\n",
        "# Display the image and mask\n",
        "display([image, mask])\n"
      ],
      "metadata": {
        "id": "kX2J96NMazxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(x_test)\n",
        "print(model_history.history.keys())"
      ],
      "metadata": {
        "id": "3hnnmc29bEEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot accuracy per iteration\n",
        "plt.plot(model_history.history['categorical_accuracy'], label='train_acc')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training Accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Plot loss per iteration\n",
        "plt.plot(model_history.history['loss'], label='train_loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OdqOxE3EbI6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Integrated Stacking Model**"
      ],
      "metadata": {
        "id": "MDjasIhAbOjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "id": "LHoeObqdbRcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import keras.models as M\n",
        "import keras.layers as L\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from IPython.display import clear_output\n",
        "import keras"
      ],
      "metadata": {
        "id": "aEgGllGfbTyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, to visualise our dataset\n",
        "\n",
        "Note: we have to use the composite image, then we have to add the path of the composite image folder into this\n"
      ],
      "metadata": {
        "id": "ERHiXd2Rbd4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tifffile as tiff\n",
        "\n",
        "# Set the folder path containing the images\n",
        "folder_path = \"/kaggle/input/ant-hv-may-oct\"\n",
        "\n",
        "# Get a list of files in the folder\n",
        "file_list = os.listdir(folder_path)\n",
        "\n",
        "# Create a subplot grid to display the images\n",
        "num_images = len(file_list)\n",
        "num_rows = int(np.ceil(np.sqrt(num_images)))\n",
        "num_cols = int(np.ceil(num_images / num_rows))\n",
        "\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
        "\n",
        "# Iterate over each file in the folder\n",
        "for i, file_name in enumerate(file_list):\n",
        "    # Check if the file is an image (TIFF format)\n",
        "    if file_name.lower().endswith('.tiff') or file_name.lower().endswith('.tiff'):\n",
        "        # Get the directory path of the image file\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "        # Load and display the image using tifffile\n",
        "        image = tiff.imread(file_path)\n",
        "\n",
        "        # Determine the subplot indices\n",
        "        row_idx = i // num_cols\n",
        "        col_idx = i % num_cols\n",
        "\n",
        "        # Display the image in the corresponding subplot\n",
        "        axes[row_idx, col_idx].imshow(image, cmap='gray')\n",
        "        axes[row_idx, col_idx].axis('off')\n",
        "\n",
        "# Adjust the spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vPJHVS_ubY1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization"
      ],
      "metadata": {
        "id": "j_OOXiqMboLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Function to perform Min-Max normalization\n",
        "def normalize_backscattering(data):\n",
        "    min_value = np.min(data)\n",
        "    max_value = np.max(data)\n",
        "    normalized_data = 255 * (data - min_value) / (max_value - min_value)\n",
        "    normalized_data = normalized_data.astype(np.uint8)\n",
        "    return normalized_data\n",
        "\n",
        "# Folder path containing the TIFF files\n",
        "folder_path = '/kaggle/input/ant-hv-may-oct'  # Replace this with the actual path to your folder\n",
        "\n",
        "# Output folder for the normalized TIFF files\n",
        "norm_folder = '/kaggle/working/norm_data'  # Replace this with the desired output path\n",
        "\n",
        "# Check if the folder exists\n",
        "if not os.path.exists(folder_path):\n",
        "    print(f\"Folder not found: {folder_path}\")\n",
        "else:\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(norm_folder):\n",
        "        os.makedirs(norm_folder)\n",
        "\n",
        "    # Loop through each TIFF file in the folder\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.tiff') or filename.endswith('.tif'):\n",
        "            # Read the TIFF file\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            backscattering_data = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "            # Perform Min-Max normalization\n",
        "            normalized_data = normalize_backscattering(backscattering_data)\n",
        "\n",
        "            # Print the minimum and maximum values in the normalized backscattering data\n",
        "            min_value = np.min(normalized_data)\n",
        "            max_value = np.max(normalized_data)\n",
        "            print(f\"File: {filename}\")\n",
        "            print(\"Minimum value:\", min_value)\n",
        "            print(\"Maximum value:\", max_value)\n",
        "            print(\"\\n\")\n",
        "\n",
        "            # Save the normalized data as a new TIFF file\n",
        "            new_filename = \"normalized_\" + filename\n",
        "            new_file_path = os.path.join(norm_folder, new_filename)\n",
        "            cv2.imwrite(new_file_path, normalized_data)\n",
        "\n",
        "print(\"Normalization and saving complete!\")\n"
      ],
      "metadata": {
        "id": "1ufKt2PabhmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This code is for composite image dataset\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "import os\n",
        "import tifffile\n",
        "\n",
        "def convert_to_db(image):\n",
        "    # Replace 0 values with a small non-zero value (e.g., 1e-9)\n",
        "    image[image == 0] = 1e-9\n",
        "\n",
        "    # Clip the image array to avoid very large values before dB conversion\n",
        "    min_clip_value = 1e-9\n",
        "    max_clip_value = 1e9\n",
        "    image = np.clip(image, min_clip_value, max_clip_value)\n",
        "\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        db_image = 10 * np.log10(image)\n",
        "    db_image[np.isinf(db_image)] = np.nan\n",
        "    return db_image\n",
        "\n",
        "def generate_mask_lib(db_image):\n",
        "    # Define the threshold values for different ice types in dB\n",
        "    threshold_ice_free = [-np.inf,0]  # Ice Free threshold\n",
        "    threshold_firstyearice = [0, 4]  # First-Year Ice threshold\n",
        "    threshold_ice_bergs = [4,6]  # Ice Covered threshold\n",
        "    threshold_multiyearice = [6, np.inf]  # Multi-Year Ice threshold\n",
        "\n",
        "\n",
        "    # Generate the mask library based on the dB image and threshold values\n",
        "    mask_ice_free = (db_image >= threshold_ice_free[0]) & (db_image <= threshold_ice_free[1])\n",
        "    mask_firstyearice = (db_image >= threshold_firstyearice[0]) & (db_image <= threshold_firstyearice[1])\n",
        "    mask_ice_bergs = (db_image >= threshold_ice_bergs[0]) & (db_image <= threshold_ice_bergs[1])\n",
        "    mask_multiyearice = (db_image >= threshold_multiyearice[0]) & (db_image <= threshold_multiyearice[1])\n",
        "\n",
        "\n",
        "    mask_lib = {\n",
        "        'Ice Free': mask_ice_free.astype(int),\n",
        "        'First-Year Ice': mask_firstyearice.astype(int),\n",
        "        'Ice bergs': mask_ice_bergs.astype(int),\n",
        "        'Multi-Year Ice': mask_multiyearice.astype(int),\n",
        "    }\n",
        "\n",
        "    return mask_lib\n",
        "\n",
        "# Function to map backscattering values to label\n",
        "def map_backscatter_to_label(backscatter):\n",
        "    if -np.inf <= backscatter <= 0:\n",
        "        return 0  # Ice Free\n",
        "    elif 0 <= backscatter <= 4:\n",
        "        return 1  # Ice bergs\n",
        "    elif 4 <= backscatter <= 7:\n",
        "        return 2  # Multi-Year Ice\n",
        "    elif 7<= backscatter <= np.inf:\n",
        "        return 3  # First-Year Ice\n",
        "    else:\n",
        "        return -1  # Invalid label\n",
        "\n",
        "# Folder path containing the SAR images (TIFF files)\n",
        "folder_path = \"/kaggle/working/norm_data\"\n",
        "\n",
        "# Initialize the lists to store the backscattering values and labels\n",
        "backscatter_values = []\n",
        "y = []\n",
        "X = []\n",
        "\n",
        "# Loop through the images in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    # Load the SAR image (TIFF)\n",
        "    image_path = os.path.join(folder_path, filename)\n",
        "    image_array = tifffile.imread(image_path)\n",
        "\n",
        "    # Check for invalid values in the image_array\n",
        "    if np.any(np.isnan(image_array)) or np.any(np.isinf(image_array)):\n",
        "        print(f\"Invalid values found in {filename}. Skipping...\")\n",
        "        continue\n",
        "\n",
        "    # Convert the SAR image to dB units\n",
        "    db_image = convert_to_db(image_array)\n",
        "    #print(f\"Filename: {filename}, Decibel value: {db_image}\")\n",
        "\n",
        "    # Get the backscattering value (mean or other representative metric if needed)\n",
        "    backscatter_value = np.nanmean(db_image)\n",
        "\n",
        "    print(f\"Filename: {filename}, Backscatter Value: {backscatter_value}\")\n",
        "\n",
        "    # Map the backscattering value to the label\n",
        "    label_encoded = map_backscatter_to_label(backscatter_value)\n",
        "\n",
        "    print(f\"Encoded Label: {label_encoded}\")\n",
        "\n",
        "    # Append the encoded label to the list and continue if label is invalid (-1)\n",
        "    if label_encoded != -1:\n",
        "        y.append(label_encoded)\n",
        "\n",
        "        # Resize the image to a consistent size\n",
        "        resized_image = resize(image_array, (150, 150))\n",
        "\n",
        "        X.append(resized_image)\n",
        "\n",
        "# Convert the lists to arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Print the final encoded labels\n",
        "print(\"Encoded Labels:\")\n",
        "print(y)"
      ],
      "metadata": {
        "id": "FVX3kxwjbpyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To ensure the unique lables and range is as desired"
      ],
      "metadata": {
        "id": "vmpV1FSScNPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step 1: Print the unique values in z_train\n",
        "unique_labels = np.unique(y)\n",
        "print(\"Unique labels in z:\", unique_labels)\n",
        "\n",
        "# Step 2: Check if the labels are integers and within the correct range\n",
        "num_classes = 4\n",
        "if np.issubdtype(y.dtype, np.integer):\n",
        "    min_label = np.min(y)\n",
        "    max_label = np.max(y)\n",
        "    if min_label >= 0 and max_label <= (num_classes - 1):\n",
        "        print(\"Labels are integers and within the correct range (0 to\", num_classes - 1, \")\")\n",
        "    else:\n",
        "        print(\"Labels are integers, but they are not within the correct range.\")\n",
        "        print(\"Minimum label:\", min_label, \", Maximum label:\", max_label)\n",
        "else:\n",
        "    print(\"Labels are not integers.\")"
      ],
      "metadata": {
        "id": "0hBGQvFmbwgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation"
      ],
      "metadata": {
        "id": "wDTnWA78cZh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Augmentation\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage.transform import resize\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=5,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "import os\n",
        "\n",
        "# Define the directory to save the augmented images\n",
        "save_dir = '/kaggle/working/augmented_img'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "# Create augmented images and labels\n",
        "print('Performing data augmentation')\n",
        "augmented_images = []\n",
        "augmented_labels = []\n",
        "num_augmented_samples = 3  # Number of augmented samples to generate per original image\n",
        "\n",
        "for i in range(len(X)):\n",
        "    img = X[i]\n",
        "    label = y[i]\n",
        "\n",
        "    # Reshape the image to include the channel dimension\n",
        "    img = np.expand_dims(img, axis=-1)\n",
        "\n",
        "    # Generate augmented samples\n",
        "    img_augmented_gen = datagen.flow(np.expand_dims(img, axis=0), batch_size=1, shuffle=False)\n",
        "\n",
        "    for j in range(num_augmented_samples):\n",
        "        img_augmented = img_augmented_gen.next()[0]\n",
        "\n",
        "        # Resize the augmented image to a consistent size\n",
        "        img_augmented = resize(img_augmented, (150, 150))\n",
        "\n",
        "        augmented_images.append(img_augmented)\n",
        "        augmented_labels.append(label)\n",
        "\n",
        "        # Save the augmented image\n",
        "        img_save_path = os.path.join(save_dir, f'image_{i}_{j}.tiff')\n",
        "        plt.imsave(img_save_path, img_augmented.squeeze(), cmap='gray')\n",
        "\n",
        "# Convert the lists to arrays\n",
        "augmented_images = np.array(augmented_images)\n",
        "augmented_labels = np.array(augmented_labels)\n",
        "\n",
        "augmented_labels = np.expand_dims(augmented_labels, axis=-1)\n",
        "\n",
        "\n",
        "print('Augmented images shape:', augmented_images.shape)\n",
        "print('Augmented labels shape:', augmented_labels.shape)\n",
        "print('Augmented images saved in:', save_dir)"
      ],
      "metadata": {
        "id": "y_j1iKpVcTZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(augmented_images, augmented_labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "H0taTTmSccIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shapes of X_train, X_test, y_train, y_test\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "metadata": {
        "id": "2DfslW7Yceau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "build classification model"
      ],
      "metadata": {
        "id": "yjHc5QesckLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "jrAeObyYcgjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convolutional Neural Network"
      ],
      "metadata": {
        "id": "yEuKpueUcrs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.utils import to_categorical\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "\n",
        "# Reshape the training data\n",
        "n_samples_train = X_train.shape[0]\n",
        "n_channels_train = X_train.shape[3]\n",
        "n_rows_train = X_train.shape[1]\n",
        "n_cols_train = X_train.shape[2]\n",
        "X_train_2d = X_train.reshape(n_samples_train, n_rows_train, n_cols_train, n_channels_train)\n",
        "\n",
        "# Reshape the test data\n",
        "n_samples_test = X_test.shape[0]\n",
        "n_channels_test = X_test.shape[3]\n",
        "n_rows_test = X_test.shape[1]\n",
        "n_cols_test = X_test.shape[2]\n",
        "X_test_2d = X_test.reshape(n_samples_test, n_rows_test, n_cols_test, n_channels_test)\n",
        "\n",
        "# Calculate the number of unique classes in your dataset\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "# Convert y_train to one-hot encoded format\n",
        "y_train_categorical = to_categorical(y_train, num_classes=n_classes)\n",
        "\n",
        "# Convert y_test to one-hot encoded format\n",
        "y_test_categorical = to_categorical(y_test, num_classes=n_classes)\n",
        "\n",
        "def cnn():\n",
        "    # Define the model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(n_rows_train, n_cols_train, n_channels_train)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(n_classes, activation='softmax'))  # Update the number of neurons here\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(cnn)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_2d, y_train_categorical, epochs=50, batch_size=32)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = model.predict(X_train_2d)\n",
        "y_test_pred = model.predict(X_test_2d)\n",
        "\n",
        "# Evaluate the model on the training data\n",
        "train_accuracy = model.score(X_train_2d, y_train_categorical)\n",
        "print('Training Accuracy:', train_accuracy)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_accuracy = model.score(X_test_2d, y_test_categorical)\n",
        "print('Test Accuracy:', test_accuracy)"
      ],
      "metadata": {
        "id": "thb7IAF0clxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM"
      ],
      "metadata": {
        "id": "IoH_w1wPc4g1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import matthews_corrcoef, f1_score\n",
        "\n",
        "# Reshape the training data\n",
        "n_samples_train = X_train.shape[0]\n",
        "n_features_train = np.prod(X_train.shape[1:])\n",
        "X_train_2d = X_train.reshape(n_samples_train, n_features_train)\n",
        "\n",
        "# Reshape the test data\n",
        "n_samples_test = X_test.shape[0]\n",
        "n_features_test = np.prod(X_test.shape[1:])\n",
        "X_test_2d = X_test.reshape(n_samples_test, n_features_test)\n",
        "\n",
        "# Ensure consistent number of samples between features and targets\n",
        "y_train_flat = y_train[:n_samples_train].ravel()\n",
        "y_test_flat = y_test[:n_samples_test].ravel()\n",
        "\n",
        "# Define the SVM model\n",
        "class SVMClassifier(SVC):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples = X.shape[0]\n",
        "        n_features = np.prod(X.shape[1:])\n",
        "        X_2d = X.reshape(n_samples, n_features)\n",
        "        y_flat = y.ravel()\n",
        "        return super().fit(X_2d, y_flat)\n",
        "\n",
        "    def predict(self, X):\n",
        "        n_samples = X.shape[0]\n",
        "        n_features = np.prod(X.shape[1:])\n",
        "        X_2d = X.reshape(n_samples, n_features)\n",
        "        return super().predict(X_2d)\n",
        "\n",
        "# Define the SVM classifier\n",
        "svm_rbf = SVMClassifier(kernel='rbf', gamma=2, C=1)\n",
        "\n",
        "# Fit the SVM model\n",
        "svm_rbf.fit(X_train_2d, y_train_flat)\n",
        "\n",
        "# Define the estimators list\n",
        "estimator_list = [\n",
        "    ('svm', SVMClassifier(gamma='scale'))\n",
        "]\n",
        "\n",
        "# Instantiate the VotingClassifier with 'hard' voting\n",
        "voting_classifier = VotingClassifier(estimators=estimator_list, voting='hard')\n",
        "\n",
        "# Fit the VotingClassifier\n",
        "voting_classifier.fit(X_train_2d, y_train_flat)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = voting_classifier.predict(X_train_2d)\n",
        "y_test_pred = voting_classifier.predict(X_test_2d)\n",
        "\n",
        "# Calculate MCC and F1-score for training set\n",
        "train_mcc = matthews_corrcoef(y_train_flat, y_train_pred)\n",
        "train_f1_macro = f1_score(y_train_flat, y_train_pred, average='macro')\n",
        "train_f1_micro = f1_score(y_train_flat, y_train_pred, average='micro')\n",
        "\n",
        "# Calculate MCC and F1-score for test set\n",
        "test_mcc = matthews_corrcoef(y_test_flat, y_test_pred)\n",
        "test_f1_macro = f1_score(y_test_flat, y_test_pred, average='macro')\n",
        "test_f1_micro = f1_score(y_test_flat, y_test_pred, average='micro')\n",
        "\n",
        "# Print the MCC and F1-score\n",
        "print('Training set:')\n",
        "print('MCC:', train_mcc)\n",
        "print('F1-score (macro):', train_f1_macro)\n",
        "print('F1-score (micro):', train_f1_micro)\n",
        "print('------------------------')\n",
        "print('Test set:')\n",
        "print('MCC:', test_mcc)\n",
        "print('F1-score (macro):', test_f1_macro)\n",
        "print('F1-score (micro):', test_f1_micro)"
      ],
      "metadata": {
        "id": "vtOrKIbjcxqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Network"
      ],
      "metadata": {
        "id": "97E2FeEDdEqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score\n",
        "\n",
        "# Reshape the training data\n",
        "n_samples_train = X_train.shape[0]\n",
        "n_features_train = np.prod(X_train.shape[1:])\n",
        "X_train_2d = X_train.reshape(n_samples_train, n_features_train)\n",
        "\n",
        "# Reshape the test data\n",
        "n_samples_test = X_test.shape[0]\n",
        "n_features_test = np.prod(X_test.shape[1:])\n",
        "X_test_2d = X_test.reshape(n_samples_test, n_features_test)\n",
        "\n",
        "# Flatten the target variable\n",
        "y_train_flat = y_train.ravel()\n",
        "y_test_flat = y_test.ravel()\n",
        "\n",
        "# Define the MLPClassifier model\n",
        "mlp = MLPClassifier(alpha=1, max_iter=1000, random_state=42)  # Add random_state for reproducibility\n",
        "\n",
        "# Fit the MLPClassifier model\n",
        "mlp.fit(X_train_2d, y_train_flat)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = mlp.predict(X_train_2d)\n",
        "y_test_pred = mlp.predict(X_test_2d)\n",
        "\n",
        "# Training set performance\n",
        "mlp_train_accuracy = accuracy_score(y_train_flat, y_train_pred)  # Calculate Accuracy\n",
        "mlp_train_mcc = matthews_corrcoef(y_train_flat, y_train_pred)  # Calculate MCC\n",
        "mlp_train_f1 = f1_score(y_train_flat, y_train_pred, average='weighted')  # Calculate F1-score\n",
        "\n",
        "# Test set performance\n",
        "mlp_test_accuracy = accuracy_score(y_test_flat, y_test_pred)  # Calculate Accuracy\n",
        "mlp_test_mcc = matthews_corrcoef(y_test_flat, y_test_pred)  # Calculate MCC\n",
        "mlp_test_f1 = f1_score(y_test_flat, y_test_pred, average='weighted')  # Calculate F1-score\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy:', mlp_train_accuracy)\n",
        "print('- MCC:', mlp_train_mcc)\n",
        "print('- F1 score:', mlp_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy:', mlp_test_accuracy)\n",
        "print('- MCC:', mlp_test_mcc)\n",
        "print('- F1 score:', mlp_test_f1)\n"
      ],
      "metadata": {
        "id": "Pa2-DuQZcx1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stacking all three above models ( CNN, NN, SVM) through logistic regression validating the model and visualizing with confusion matrix"
      ],
      "metadata": {
        "id": "zYPhd7_VdOAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score, confusion_matrix\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate some random data for demonstration\n",
        "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base classifiers\n",
        "svm = SVC()\n",
        "mlp = MLPClassifier()\n",
        "\n",
        "# Define estimators\n",
        "estimator_list = [('svm_rbf', svm), ('mlp', mlp)]\n",
        "\n",
        "# Build stack model\n",
        "stack_model = StackingClassifier(estimators=estimator_list, final_estimator=LogisticRegression())\n",
        "\n",
        "# Train stacked model\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = stack_model.predict(X_train)\n",
        "y_test_pred = stack_model.predict(X_test)\n",
        "\n",
        "# Training set model performance\n",
        "stack_model_train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "stack_model_train_mcc = matthews_corrcoef(y_train, y_train_pred)\n",
        "stack_model_train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
        "\n",
        "# Test set model performance\n",
        "stack_model_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "stack_model_test_mcc = matthews_corrcoef(y_test, y_test_pred)\n",
        "stack_model_test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "print('Model performance for Training set')\n",
        "print('- Accuracy:', stack_model_train_accuracy)\n",
        "print('- MCC:', stack_model_train_mcc)\n",
        "print('- F1 score:', stack_model_train_f1)\n",
        "print('----------------------------------')\n",
        "print('Model performance for Test set')\n",
        "print('- Accuracy:', stack_model_test_accuracy)\n",
        "print('- MCC:', stack_model_test_mcc)\n",
        "print('- F1 score:', stack_model_test_f1)\n",
        "\n",
        "\n",
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized Confusion Matrix\")\n",
        "    else:\n",
        "        print('Confusion Matrix, without Normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "\n",
        "\n",
        "# Calculate confusion matrix for training set\n",
        "train_confusion_matrix = confusion_matrix(y_train, y_train_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "plot_confusion_matrix(train_confusion_matrix, classes=np.unique(y_train), normalize=False, title=\"Confusion Matrix (Training Set)\")\n",
        "plt.show()\n",
        "\n",
        "# Calculate confusion matrix for test set\n",
        "test_confusion_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "plt.figure(figsize=(10, 8))\n",
        "plot_confusion_matrix(test_confusion_matrix, classes=np.unique(y_test), normalize=False, title=\"Confusion Matrix (Test Set)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0YkLrRnydGdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Results"
      ],
      "metadata": {
        "id": "Ikgw-UjCdf7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "acc_train_list = {\n",
        "#'svm_rbf': svm_rbf_train_accuracy,\n",
        "'cnn': mlp_train_accuracy,\n",
        "'stack': stack_model_train_accuracy}\n",
        "\n",
        "mcc_train_list = {\n",
        "'svm_rbf': train_mcc,\n",
        "'mlp': mlp_train_mcc,\n",
        "'stack': stack_model_train_mcc}\n",
        "\n",
        "f1_train_list = {\n",
        "'svm_rbf': train_f1_micro,\n",
        "'mlp': mlp_train_f1,\n",
        "'stack': stack_model_train_f1}"
      ],
      "metadata": {
        "id": "UnVVKl-TdewR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_train_list"
      ],
      "metadata": {
        "id": "WEwcVc2mdjI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcc_train_list"
      ],
      "metadata": {
        "id": "8ztH-NWJdj0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_train_list"
      ],
      "metadata": {
        "id": "w7Gw2DTZdmB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "acc_df = pd.DataFrame.from_dict(acc_train_list, orient='index', columns=['Accuracy'])\n",
        "mcc_df = pd.DataFrame.from_dict(mcc_train_list, orient='index', columns=['MCC'])\n",
        "f1_df = pd.DataFrame.from_dict(f1_train_list, orient='index', columns=['F1'])\n",
        "df = pd.concat([acc_df, mcc_df, f1_df], axis=1)"
      ],
      "metadata": {
        "id": "f2d223urdoAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('results.csv')"
      ],
      "metadata": {
        "id": "Hmx9Xke6dqrm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}